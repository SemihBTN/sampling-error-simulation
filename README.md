Ã–rnekleme SimÃ¼lasyonu: SayÄ±larÄ±n GÃ¼cÃ¼
HiÃ§ merak ettiniz mi; bir ankette 10 kiÅŸiyle konuÅŸmak neden yetmez de binlerce kiÅŸiye ulaÅŸmaya Ã§alÄ±ÅŸÄ±rÄ±z? Bu proje, "Daha fazla veri, daha az hata" ilkesini Python kullanarak gÃ¶rsel bir kanÄ±ta dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yor.

ğŸ” Neyi Ä°nceledim?
Ä°statistikte Basit Rastgele Ã–rnekleme yaparken, kÃ¼Ã§Ã¼k gruplar bizi yanÄ±ltabilir. Åans eseri hep uÃ§ deÄŸerleri (Ã§ok yaÅŸlÄ±lar veya Ã§ok zenginler gibi) seÃ§ebiliriz. Ben bu "ÅŸans faktÃ¶rÃ¼nÃ¼n" (varyans) veri boyutu arttÄ±kÃ§a nasÄ±l etkisiz hale geldiÄŸini simÃ¼le ettim.

ğŸ› ï¸ Ne YaptÄ±m? (Hokus Pokus KÄ±smÄ±)
Ham Veri: Ã–nce 10.000 kiÅŸilik hayali bir topluluk oluÅŸturdum.

ZikzaklarÄ± Silmek: Tek bir Ã§ekim yapÄ±p "tamam oldu" demedim. Her Ã¶rneklem boyutu iÃ§in 100 farklÄ± deneme yapÄ±p bunlarÄ±n ortalamasÄ±nÄ± aldÄ±m. Buna "gÃ¼rÃ¼ltÃ¼ temizleme" diyoruz.

SonuÃ§: Ortaya Ã§Ä±kan grafik, rastgeleliÄŸin iÃ§indeki o mÃ¼kemmel dÃ¼zeni; yani veri arttÄ±kÃ§a hatanÄ±n nasÄ±l sÄ±fÄ±ra sÃ¼zÃ¼ldÃ¼ÄŸÃ¼nÃ¼ gÃ¶steriyor.

ğŸ’¡ Bana Ne Ã–ÄŸretti?
Bu Ã§alÄ±ÅŸma sadece bir grafik deÄŸil; BÃ¼yÃ¼k SayÄ±lar YasasÄ±'nÄ±n (Law of Large Numbers) Ã§alÄ±ÅŸan bir Ã¶rneÄŸi. Veri biliminde "yeterli Ã¶rneklem" kavramÄ±nÄ±n neden hayati olduÄŸunu ve kÃ¼Ã§Ã¼k verilerle karar vermenin ne kadar riskli olduÄŸunu bu sayede koda dÃ¶kmÃ¼ÅŸ oldum.
